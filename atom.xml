<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>SIGMA&#39;s BLOG</title>
  
  <subtitle>CB116</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2017-12-22T13:19:35.444Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Junyan Wu</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Hello World</title>
    <link href="http://yoursite.com/2017/12/22/hello-world/"/>
    <id>http://yoursite.com/2017/12/22/hello-world/</id>
    <published>2017-12-22T13:19:35.444Z</published>
    <updated>2017-12-22T13:19:35.444Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>GCRN代码解读</title>
    <link href="http://yoursite.com/2017/12/21/GCRN/"/>
    <id>http://yoursite.com/2017/12/21/GCRN/</id>
    <published>2017-12-21T03:05:23.000Z</published>
    <updated>2017-12-22T13:23:06.273Z</updated>
    
    <content type="html"><![CDATA[<ul><li>论文及源代码：<a href="https://github.com/youngjoo-epfl/gconvRNN" target="_blank" rel="noopener">点击这里</a></li></ul><p>由于涉及比较多的公式，而github不支持MathJax或者LaTeX，所以如果想获得更好的阅读体验请安装chrome插件<a href="https://chrome.google.com/webstore/detail/github-with-mathjax/ioemnmodlmafdkllaclgeombjnmnbima" target="_blank" rel="noopener">GitHub with MathJax</a>，或者有更好的方法恳请告知。</p><p>若发现存在错误，欢迎指正。</p><p>GCN，是基于Spectral Graph Theory所研究出来的一种方法，它主要的好处是利用了SGT里面一些已有的结论和方法，来得到图的性质。GCRN是一个将GCN和RNN结合起来使用的模型，能处理具有空间和时序的数据。</p><p>源代码的目录结构：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">gconvRNN</span><br><span class="line">  - datasets</span><br><span class="line">    - ptb.char.test.txt</span><br><span class="line">    - ptb.char.train.txt</span><br><span class="line">    - ptb.char.valid.txt</span><br><span class="line">  - gcrn_main.py  # 整个程序的入口</span><br><span class="line">  - config.py  # 用于配置超参数</span><br><span class="line">  - graph.py  # 与图相关的操作，比如laplacian矩阵</span><br><span class="line">  - model.py  # 模型的定义</span><br><span class="line">  - trainer.py  # 定义了训练过程</span><br><span class="line">  - utils.py  # 数据预处理、工具</span><br></pre></td></tr></table></figure><p>在源码中，GCRN用于预测单词字符序列</p><p>本文从三个方面讲解GCRN源码的处理思路</p><ul><li>数据预处理</li><li>GCRN实现思路</li><li>开始训练</li><li>代码附录</li></ul><h3 id="数据预处理："><a href="#数据预处理：" class="headerlink" title="数据预处理："></a>数据预处理：</h3><p><em>train\valid\test 数据集的格式都是一样的：</em></p><blockquote><p>a e r <em> b a n k n o t e </em> b e r l i t z <em> c a l l o w a y </em> c e n t r u s t <em> c l u e t t </em> f r o m s t e i n <em> g i t a n o </em> g u t e r m a n <em> h y d r o - q u e b e c </em> i p o <em> k i a </em> m e m o t e c <em> m l x </em> n a h b <em> p u n t s </em> r a k e <em> r e g a t t a </em> r u b e n s <em> s i m </em> s n a c k - f o o d <em> s s a n g y o n g </em> s w a p o <em> w a c h t e r<br> p i e r r e </em> &lt; u n k &gt; <em> N </em> y e a r s <em> o l d </em> w i l l <em> j o i n </em> t h e <em> b o a r d </em> a s <em> a </em> n o n e x e c u t i v e <em> d i r e c t o r </em> n o v . <em> N<br> m r . </em> &lt; u n k &gt; <em> i s </em> c h a i r m a n <em> o f </em> &lt; u n k &gt; <em> n . v . </em> t h e <em> d u t c h </em> p u b l i s h i n g _ g r o u p</p></blockquote><ul><li><code>UNK</code> - “unknown token” - is used to replace the rare words that did not fit in your vocabulary. So your sentence <code>My name is guotong1998</code> will be translated into <code>My name is _unk_</code></li></ul><p><strong>1. 将句子按字典映射成数字序列</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">for every sentences:</span><br><span class="line">  在句子后面加“|”（人为地添加句子的结束标识符）</span><br><span class="line">  将句子里面的*每个字符*映射成该字符在字典中*对应的数字*</span><br></pre></td></tr></table></figure><p>例如：</p><p>p i e r r e <em> &lt; u n k &gt; </em> N <em> y e a r s </em> o l d <em> w i l l </em> j o i n <em> t h e </em> b o a r d <em> a s </em> a <em> n o n e x e c u t i v e </em> d i r e c t o r <em> n o v . </em> N |</p><p>[24, 10, 1, 2, 2, 1, 3, 27, 15, 5, 6, 28, 3, 29, 3, 14, 1, 0, 2, 16, 3, 7, 9, 21, 3, 13, 10, 9, 9, 3, 30, 7, 10, 5, 3, 8, 20, 1, 3, 4, 7, 0, 2, 21, 3, 0, 16, 3, 0, 3, 5, 7, 5, 1, 25, 1, 12, 15, 8, 10, 31, 1, 3, 21, 10, 2, 1, 12, 8, 7, 2, 3, 5, 7, 31, 32, 3, 29, 26]</p><p><strong>2. 构造邻接矩阵</strong></p><p><img src="./images/adj.png" alt=""></p><p>得到邻接矩阵的值：</p><p><img src="./images/adj_value.png" alt=""></p><h3 id="GCRN实现思路："><a href="#GCRN实现思路：" class="headerlink" title="GCRN实现思路："></a>GCRN实现思路：</h3><p>GCRN = GCN + RNN。</p><p><em>公式</em>：</p><p><img src="./images/gconv.png" alt=""></p><p><img src="./images/lstm_func.png" alt=""></p><p><strong>但是</strong> 代码中的实现方式稍有不同</p><p><strong>GCN</strong> ：</p><p>$$L = adj/adj.max$$</p><p>$$Laplacian = \frac{2L}{lmax} - I$$</p><p>$$T<em>k(x) = 2LT</em>{k-1}(x)-T_{k-2}(x)$$</p><p>每次得到的 $T_k(x)$ 都与x做concat，最后得到的x与W相乘</p><p><strong>LSTM</strong> ：</p><p><img src="./images/gcn_lstm.png" alt=""></p><h3 id="开始训练"><a href="#开始训练" class="headerlink" title="开始训练"></a>开始训练</h3><p>数据预处理 -&gt; model定义 -&gt; train</p><p><img src="./images/dataflow.png" alt=""></p><p>输出<code>ouput</code>的shape为(batch_size, num_node, num_unit) —— (20, 50, 50)。由于设置了有50个LSTM units，所以这里需要使所有units的输出做线性变换，使其变为一个值：</p><ul><li><code>prediction = output * W -b</code>，这里的<code>prediction</code>的shape为(20, 50, 1)</li></ul><p>那么，所有时刻的输出的shape为(50, 20, 50, 1)</p><h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><p><strong>GCN实现方法</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cheby_conv</span><span class="params">(x, L, lmax, feat_out, K, W)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    x : [batch_size, N_node, feat_in] - input of each time step</span></span><br><span class="line"><span class="string">    nSample : number of samples = batch_size</span></span><br><span class="line"><span class="string">    nNode : number of node in graph</span></span><br><span class="line"><span class="string">    feat_in : number of input feature</span></span><br><span class="line"><span class="string">    feat_out : number of output feature</span></span><br><span class="line"><span class="string">    L : laplacian</span></span><br><span class="line"><span class="string">    lmax : ?</span></span><br><span class="line"><span class="string">    K : size of kernel(number of cheby coefficients)</span></span><br><span class="line"><span class="string">    W : cheby_conv weight [K * feat_in, feat_out]</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    nSample, nNode, feat_in = x.get_shape()</span><br><span class="line">    nSample, nNode, feat_in = int(nSample), int(nNode), int(feat_in)</span><br><span class="line">    L = graph.rescale_L(L, lmax) <span class="comment">#What is this operation?? --&gt; rescale Laplacian</span></span><br><span class="line">    L = L.tocoo()</span><br><span class="line"></span><br><span class="line">    indices = np.column_stack((L.row, L.col))</span><br><span class="line">    L = tf.SparseTensor(indices, L.data, L.shape)</span><br><span class="line">    L = tf.sparse_reorder(L)</span><br><span class="line"></span><br><span class="line">    x0 = tf.transpose(x, perm=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>]) <span class="comment">#change it to [nNode, feat_in, nSample]</span></span><br><span class="line">    x0 = tf.reshape(x0, [nNode, feat_in*nSample])</span><br><span class="line">    x = tf.expand_dims(x0, <span class="number">0</span>) <span class="comment"># make it [1, nNode, feat_in*nSample]</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">concat</span><span class="params">(x, x_)</span>:</span></span><br><span class="line">        x_ = tf.expand_dims(x_, <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> tf.concat([x, x_], axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> K &gt; <span class="number">1</span>:</span><br><span class="line">        x1 = tf.sparse_tensor_dense_matmul(L, x0)</span><br><span class="line">        x = concat(x, x1)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">2</span>, K):</span><br><span class="line">        x2 = <span class="number">2</span> * tf.sparse_tensor_dense_matmul(L, x1) - x0</span><br><span class="line">        x = concat(x, x2)</span><br><span class="line">        x0, x1 = x1, x2</span><br><span class="line"></span><br><span class="line">    x = tf.reshape(x, [K, nNode, feat_in, nSample])</span><br><span class="line">    x = tf.transpose(x, perm=[<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>])</span><br><span class="line">    x = tf.reshape(x, [nSample*nNode, feat_in*K])</span><br><span class="line"></span><br><span class="line">    x = tf.matmul(x, W) <span class="comment">#No Bias term?? -&gt; Yes</span></span><br><span class="line">    out = tf.reshape(x, [nSample, nNode, feat_out])</span><br><span class="line">    <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure><p><strong>LSTM实现方法</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__call__</span><span class="params">(self, inputs, state, scope=None)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(scope <span class="keyword">or</span> type(self).__name__):</span><br><span class="line">        <span class="keyword">if</span> self._state_is_tuple:</span><br><span class="line">            c, h = state</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            c, h = tf.split(value=state, num_or_size_splits=<span class="number">2</span>, axis=<span class="number">1</span>)</span><br><span class="line">        laplacian = self._laplacian</span><br><span class="line">        lmax = self._lmax</span><br><span class="line">        K = self._K</span><br><span class="line">        feat_in = self._feat_in</span><br><span class="line"></span><br><span class="line">        <span class="comment">#The inputs : [batch_size, nNode, feat_in, nTime?] size tensor</span></span><br><span class="line">        <span class="keyword">if</span> feat_in <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">            <span class="comment">#Take out the shape of input</span></span><br><span class="line">            batch_size, nNode, feat_in = inputs.get_shape()</span><br><span class="line">            print(<span class="string">"hey!"</span>)</span><br><span class="line"></span><br><span class="line">        feat_out = self._num_units</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> K <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">            K = <span class="number">2</span></span><br><span class="line"></span><br><span class="line">        scope = tf.get_variable_scope()</span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(scope) <span class="keyword">as</span> scope:</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                <span class="comment">#Need four diff Wconv weight + for Hidden weight</span></span><br><span class="line">                Wzxt = tf.get_variable(<span class="string">"Wzxt"</span>, [K*feat_in, feat_out], dtype=tf.float32,</span><br><span class="line">                                       initializer=tf.random_uniform_initializer(minval=<span class="number">-0.1</span>, maxval=<span class="number">0.1</span>))</span><br><span class="line">                Wixt = tf.get_variable(<span class="string">"Wixt"</span>, [K*feat_in, feat_out], dtype=tf.float32,</span><br><span class="line">                                       initializer=tf.random_uniform_initializer(minval=<span class="number">-0.1</span>, maxval=<span class="number">0.1</span>))</span><br><span class="line">                Wfxt = tf.get_variable(<span class="string">"Wfxt"</span>, [K*feat_in, feat_out], dtype=tf.float32,</span><br><span class="line">                                       initializer=tf.random_uniform_initializer(minval=<span class="number">-0.1</span>, maxval=<span class="number">0.1</span>))</span><br><span class="line">                Woxt = tf.get_variable(<span class="string">"Woxt"</span>, [K*feat_in, feat_out], dtype=tf.float32,</span><br><span class="line">                                       initializer=tf.random_uniform_initializer(minval=<span class="number">-0.1</span>, maxval=<span class="number">0.1</span>))</span><br><span class="line"></span><br><span class="line">                Wzht = tf.get_variable(<span class="string">"Wzht"</span>, [K*feat_out, feat_out], dtype=tf.float32,</span><br><span class="line">                                       initializer=tf.random_uniform_initializer(minval=<span class="number">-0.1</span>, maxval=<span class="number">0.1</span>))</span><br><span class="line">                Wiht = tf.get_variable(<span class="string">"Wiht"</span>, [K*feat_out, feat_out], dtype=tf.float32,</span><br><span class="line">                                       initializer=tf.random_uniform_initializer(minval=<span class="number">-0.1</span>, maxval=<span class="number">0.1</span>))</span><br><span class="line">                Wfht = tf.get_variable(<span class="string">"Wfht"</span>, [K*feat_out, feat_out], dtype=tf.float32,</span><br><span class="line">                                       initializer=tf.random_uniform_initializer(minval=<span class="number">-0.1</span>, maxval=<span class="number">0.1</span>))</span><br><span class="line">                Woht = tf.get_variable(<span class="string">"Woht"</span>, [K*feat_out, feat_out], dtype=tf.float32,</span><br><span class="line">                                       initializer=tf.random_uniform_initializer(minval=<span class="number">-0.1</span>, maxval=<span class="number">0.1</span>))</span><br><span class="line">            <span class="keyword">except</span> ValueError:</span><br><span class="line">                scope.reuse_variables()</span><br><span class="line">                Wzxt = tf.get_variable(<span class="string">"Wzxt"</span>, [K*feat_in, feat_out], dtype=tf.float32,</span><br><span class="line">                                       initializer=tf.random_uniform_initializer(minval=<span class="number">-0.1</span>, maxval=<span class="number">0.1</span>))</span><br><span class="line">                Wixt = tf.get_variable(<span class="string">"Wixt"</span>, [K*feat_in, feat_out], dtype=tf.float32,</span><br><span class="line">                                       initializer=tf.random_uniform_initializer(minval=<span class="number">-0.1</span>, maxval=<span class="number">0.1</span>))</span><br><span class="line">                Wfxt = tf.get_variable(<span class="string">"Wfxt"</span>, [K*feat_in, feat_out], dtype=tf.float32,</span><br><span class="line">                                       initializer=tf.random_uniform_initializer(minval=<span class="number">-0.1</span>, maxval=<span class="number">0.1</span>))</span><br><span class="line">                Woxt = tf.get_variable(<span class="string">"Woxt"</span>, [K*feat_in, feat_out], dtype=tf.float32,</span><br><span class="line">                                       initializer=tf.random_uniform_initializer(minval=<span class="number">-0.1</span>, maxval=<span class="number">0.1</span>))</span><br><span class="line"></span><br><span class="line">                Wzht = tf.get_variable(<span class="string">"Wzht"</span>, [K*feat_out, feat_out], dtype=tf.float32,</span><br><span class="line">                                       initializer=tf.random_uniform_initializer(minval=<span class="number">-0.1</span>, maxval=<span class="number">0.1</span>))</span><br><span class="line">                Wiht = tf.get_variable(<span class="string">"Wiht"</span>, [K*feat_out, feat_out], dtype=tf.float32,</span><br><span class="line">                                       initializer=tf.random_uniform_initializer(minval=<span class="number">-0.1</span>, maxval=<span class="number">0.1</span>))</span><br><span class="line">                Wfht = tf.get_variable(<span class="string">"Wfht"</span>, [K*feat_out, feat_out], dtype=tf.float32,</span><br><span class="line">                                       initializer=tf.random_uniform_initializer(minval=<span class="number">-0.1</span>, maxval=<span class="number">0.1</span>))</span><br><span class="line">                Woht = tf.get_variable(<span class="string">"Woht"</span>, [K*feat_out, feat_out], dtype=tf.float32,</span><br><span class="line">                                       initializer=tf.random_uniform_initializer(minval=<span class="number">-0.1</span>, maxval=<span class="number">0.1</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            bzt = tf.get_variable(<span class="string">"bzt"</span>, [feat_out])</span><br><span class="line">            bit = tf.get_variable(<span class="string">"bit"</span>, [feat_out])</span><br><span class="line">            bft = tf.get_variable(<span class="string">"bft"</span>, [feat_out])</span><br><span class="line">            bot = tf.get_variable(<span class="string">"bot"</span>, [feat_out])</span><br><span class="line"></span><br><span class="line">            <span class="comment"># gconv Calculation</span></span><br><span class="line">            zxt = cheby_conv(inputs, laplacian, lmax, feat_out, K, Wzxt)</span><br><span class="line">            zht = cheby_conv(h, laplacian, lmax, feat_out, K, Wzht)</span><br><span class="line">            zt  = zxt + zht + bzt</span><br><span class="line">            zt  = tf.tanh(zt)</span><br><span class="line"></span><br><span class="line">            ixt = cheby_conv(inputs, laplacian, lmax, feat_out, K, Wixt)</span><br><span class="line">            iht = cheby_conv(h, laplacian, lmax, feat_out, K, Wiht)</span><br><span class="line">            it  = ixt + iht + bit</span><br><span class="line">            it  = tf.sigmoid(it)</span><br><span class="line"></span><br><span class="line">            fxt = cheby_conv(inputs, laplacian, lmax, feat_out, K, Wfxt)</span><br><span class="line">            fht = cheby_conv(h, laplacian, lmax, feat_out, K, Wfht)</span><br><span class="line">            ft  = fxt + fht + bft</span><br><span class="line">            ft  = tf.sigmoid(ft)</span><br><span class="line"></span><br><span class="line">            oxt = cheby_conv(inputs, laplacian, lmax, feat_out, K, Woxt)</span><br><span class="line">            oht = cheby_conv(h, laplacian, lmax, feat_out, K, Woht)</span><br><span class="line">            ot  = oxt + oht + bot</span><br><span class="line">            ot  = tf.sigmoid(ot)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># c</span></span><br><span class="line">            new_c = ft*c + it*zt</span><br><span class="line"></span><br><span class="line">            <span class="comment"># h</span></span><br><span class="line">            new_h = ot*tf.tanh(new_c)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> self._state_is_tuple:</span><br><span class="line">                new_state = LSTMStateTuple(new_c, new_h)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                new_state = tf.concat([new_c, new_h], <span class="number">1</span>)</span><br><span class="line">            <span class="keyword">return</span> new_h, new_state</span><br></pre></td></tr></table></figure><h5 id="其他变量"><a href="#其他变量" class="headerlink" title="其他变量"></a>其他变量</h5><table><thead><tr><th>变量</th><th>shape</th><th>meaning</th></tr></thead><tbody><tr><td>rnn_input</td><td>(20, 50, 1, 50)</td><td>(batch_size, num_node, feat_in, num_time_steps)</td></tr><tr><td>rnn_input_seq</td><td>(20, 50, 1) * 50</td><td>(batch_size, num_node, feat_in) * num_time_steps</td></tr><tr><td>rnn_output</td><td>(20, 50)</td><td>(batch_size, num_time_steps)</td></tr><tr><td>rnn_output_seq</td><td>(20) * 50</td><td>(batch_size) * num_time_steps</td></tr><tr><td>num_hidden</td><td>50</td><td>隐藏层单元</td></tr><tr><td>x_batches</td><td>(5017, 20, 50)</td><td>[-1, batch_size, seq_length]</td></tr><tr><td>y_batches</td><td>(5017, 20, 50)</td><td>[-1, batch_size, seq_length]</td></tr><tr><td>outputs</td><td>(50, 20, 50, 50)</td><td>(50个时刻50个输出, batch_size, num_node, num_unit)</td></tr><tr><td>output</td><td>(20, 50, 50)</td><td>outputs的单个时刻输出(batch_size, num_node, num_unit)</td></tr></tbody></table><h3 id="Laplacian-matrix"><a href="#Laplacian-matrix" class="headerlink" title="Laplacian matrix"></a>Laplacian matrix</h3><p><img src="./images/laplacian_example.png" alt=""></p><p><strong>Properties</strong></p><p>对一个无向图$G$和他的laplacian matrix $L$，有特征值$\lambda_0 \leq \lambda_1 \leq \lambda_2 …$：</p><ul><li>L是对称的</li><li>L是半正定的（即所有$\lambda_i &gt; 0$），这可以在关联矩阵部分验证，也同样可以从Laplacian是对称并且对角占优(diagonally dominant)得出</li><li>L是M-matrix（它的非对角线上的项是负的，但它的特征值的实部为负）</li><li>行或列相加结果为0</li><li>L的最小非零特征值称为谱间隙（spectral gap）</li><li>图中连通分量的个数是拉普拉斯算子的零空间维数和0特征值的代数多重性</li><li>拉普拉斯矩阵是奇异的</li></ul><h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><ol><li>代码实现里面的公式跟论文是否真的不一样</li><li>x2 = 2 * tf.sparse_tensor_dense_matmul(L, x1) - x0 起到一个什么作用</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ul&gt;
&lt;li&gt;论文及源代码：&lt;a href=&quot;https://github.com/youngjoo-epfl/gconvRNN&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;点击这里&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;由于涉及比较多的公式，而github
      
    
    </summary>
    
    
      <category term="paper" scheme="http://yoursite.com/tags/paper/"/>
    
      <category term="gcn" scheme="http://yoursite.com/tags/gcn/"/>
    
  </entry>
  
</feed>
